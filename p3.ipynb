{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "84dca248e17b42e69ce293893d6e52da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_985d27ee4ee9442282cba60656561b87",
              "IPY_MODEL_f3a4823075b64deaaac302744a4c3065",
              "IPY_MODEL_bc9edb995ea04557b20626a81505e583"
            ],
            "layout": "IPY_MODEL_5e2abeb289b3412e9deb35fcf7aa59e2"
          }
        },
        "985d27ee4ee9442282cba60656561b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_514e0ea3ae01472f9a1f445587eda4f4",
            "placeholder": "​",
            "style": "IPY_MODEL_0e9c3045714946169590856007323c7e",
            "value": ""
          }
        },
        "f3a4823075b64deaaac302744a4c3065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79a39a0f3a164a6e8532d5d3a6a97acc",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1917c37ead9a4ed6b941193f2b9f3f6f",
            "value": 170498071
          }
        },
        "bc9edb995ea04557b20626a81505e583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8ee82cbb52e4f719764ed11e0be1d92",
            "placeholder": "​",
            "style": "IPY_MODEL_51c6fd1f8c9e452bb490b6a08367168f",
            "value": " 170499072/? [00:03&lt;00:00, 34957277.83it/s]"
          }
        },
        "5e2abeb289b3412e9deb35fcf7aa59e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "514e0ea3ae01472f9a1f445587eda4f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e9c3045714946169590856007323c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79a39a0f3a164a6e8532d5d3a6a97acc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1917c37ead9a4ed6b941193f2b9f3f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8ee82cbb52e4f719764ed11e0be1d92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c6fd1f8c9e452bb490b6a08367168f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jX3J4dfRR4e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import relu, softmax\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMjJOZJDR5v8"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    '''\n",
        "    Implement network as a custom Module subclass\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3,\n",
        "                               out_channels=64,\n",
        "                               kernel_size=11)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2,\n",
        "                                 stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=64,\n",
        "                               out_channels=128,\n",
        "                               kernel_size=3)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=128,\n",
        "                               out_channels=128,\n",
        "                               kernel_size=3)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        \n",
        "        self.fc = nn.Linear(128, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # 1st set of layers -- Conv, ReLU, MaxPool\n",
        "        x = self.conv1(x)\n",
        "        x = relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        \n",
        "        # 2nd set of layers -- Conv, ReLU\n",
        "        x = self.conv2(x)\n",
        "        x = relu(x)\n",
        "        \n",
        "        # 3rd set of layers -- Conv, ReLU\n",
        "        x = self.conv3(x)\n",
        "        x = relu(x)\n",
        "        \n",
        "        # 4th set of layers -- AvgPool\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(-1, 128)\n",
        "        \n",
        "        # 5th set of layers -- FC Linear, softmax\n",
        "        x = self.fc(x)\n",
        "        x = softmax(x, dim=1)\n",
        "        \n",
        "        return x\n",
        "\n",
        "# Transfer ConvNet onto GPU\n",
        "device = torch.device(\"cuda:0\")\n",
        "net_original = CNN().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iORQp1ixCBq"
      },
      "source": [
        "class CNN_bn(nn.Module):\n",
        "    '''\n",
        "    Implement ConvNet with batch normalization as a custom Module subclass\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(CNN_bn, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3,\n",
        "                               out_channels=64,\n",
        "                               kernel_size=11)\n",
        "\n",
        "        self.conv1_bn = nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2,\n",
        "                                 stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=64,\n",
        "                               out_channels=128,\n",
        "                               kernel_size=3)\n",
        "        \n",
        "        self.conv2_bn = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=128,\n",
        "                               out_channels=128,\n",
        "                               kernel_size=3)\n",
        "        \n",
        "        self.conv3_bn = nn.BatchNorm2d(num_features=128)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        \n",
        "        self.fc = nn.Linear(128, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # 1st set of layers -- Conv, ReLU, Batch Normalization, MaxPool\n",
        "        x = self.conv1(x)\n",
        "        x = relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.conv1_bn(x)\n",
        "\n",
        "        # 2nd set of layers -- Conv, ReLU, Batch Normalization\n",
        "        x = self.conv2(x)\n",
        "        x = relu(x)\n",
        "        x = self.conv2_bn(x)\n",
        "        \n",
        "        # 3rd set of layers -- Conv, ReLU, Batch Normalization\n",
        "        x = self.conv3(x)\n",
        "        x = relu(x)\n",
        "        x = self.conv3_bn(x)\n",
        "        \n",
        "        # 4th set of layers -- AvgPool\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(-1, 128)\n",
        "        \n",
        "        # 5th set of layers -- FC Linear, softmax\n",
        "        x = self.fc(x)\n",
        "        x = softmax(x, dim=1)\n",
        "        \n",
        "        return x\n",
        "\n",
        "# Transfer ConvNet onto GPU\n",
        "device = torch.device(\"cuda:0\")\n",
        "net_bn = CNN_bn().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukjEpDXqYFK0"
      },
      "source": [
        "class CNN_deep(nn.Module):\n",
        "    '''\n",
        "    Implement deeper ConvNet as a custom Module subclass\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(CNN_deep, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3,\n",
        "                               out_channels=64,\n",
        "                               kernel_size=3)\n",
        "\n",
        "        self.conv1_bn = nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2,\n",
        "                                    stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=64,\n",
        "                               out_channels=128,\n",
        "                               kernel_size=3)\n",
        "        \n",
        "        self.conv2_bn = nn.BatchNorm2d(num_features=128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=128,\n",
        "                               out_channels=128,\n",
        "                               kernel_size=3)\n",
        "        \n",
        "        self.conv3_bn = nn.BatchNorm2d(num_features=128)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(in_channels=128,\n",
        "                               out_channels=256,\n",
        "                               kernel_size=3)\n",
        "        \n",
        "        self.conv4_bn = nn.BatchNorm2d(num_features=256)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=256,\n",
        "                               out_channels=256,\n",
        "                               kernel_size=3)\n",
        "        \n",
        "        self.conv5_bn = nn.BatchNorm2d(num_features=256)\n",
        "\n",
        "        self.conv6 = nn.Conv2d(in_channels=256,\n",
        "                               out_channels=512,\n",
        "                               kernel_size=3)\n",
        "        \n",
        "        self.conv6_bn = nn.BatchNorm2d(num_features=512)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(512, 256)\n",
        "        \n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        \n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        # 1st convolutional layer -- Conv, ReLU, Batch Normalization, MaxPool\n",
        "        x = self.conv1(x)\n",
        "        x = relu(x)\n",
        "        x = self.conv1_bn(x)\n",
        "        x = self.maxpool(x)\n",
        "        \n",
        "        # 2nd convolutional layer -- Conv, ReLU, Batch Normalization\n",
        "        x = self.conv2(x)\n",
        "        x = relu(x)\n",
        "        x = self.conv2_bn(x)\n",
        "        \n",
        "        # 3rd convolutional layer -- Conv, ReLU, Batch Normalization\n",
        "        x = self.conv3(x)\n",
        "        x = relu(x)\n",
        "        x = self.conv3_bn(x)\n",
        "\n",
        "        # 4th convolutional layer -- Conv, ReLU, Batch Normalization\n",
        "        x = self.conv4(x)\n",
        "        x = relu(x)\n",
        "        x = self.conv4_bn(x)\n",
        "\n",
        "        # 5th convolutional layer -- Conv, ReLU, Batch Normalization\n",
        "        x = self.conv5(x)\n",
        "        x = relu(x)\n",
        "        x = self.conv5_bn(x)\n",
        "\n",
        "        # 6th convolutional layer -- Conv, ReLU, Batch Normalization\n",
        "        x = self.conv6(x)\n",
        "        x = relu(x)\n",
        "        x = self.conv6_bn(x)\n",
        "\n",
        "        # AvgPool layer\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(-1, 512)\n",
        "\n",
        "        # 1st fully connected layers -- FC Linear, ReLU\n",
        "        x = self.fc1(x)\n",
        "        x = relu(x)\n",
        "\n",
        "        # 2nd fully connected layers -- FC Linear, ReLU\n",
        "        x = self.fc2(x)\n",
        "        x = relu(x)\n",
        "\n",
        "        # 3rd set of layers -- FC Linear, softmax\n",
        "        x = self.fc3(x)\n",
        "        x = relu(x)\n",
        "        x = softmax(x, dim=1)\n",
        "        \n",
        "        return x\n",
        "\n",
        "# Transfer ConvNet onto GPU\n",
        "device = torch.device(\"cuda:0\")\n",
        "net_deep = CNN_deep().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiZiQBms_74e"
      },
      "source": [
        "# Define hyper-parameters\n",
        "batch_size = 30\n",
        "num_epochs = 150\n",
        "lr = 0.009\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHSGbyLJSd0q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "84dca248e17b42e69ce293893d6e52da",
            "985d27ee4ee9442282cba60656561b87",
            "f3a4823075b64deaaac302744a4c3065",
            "bc9edb995ea04557b20626a81505e583",
            "5e2abeb289b3412e9deb35fcf7aa59e2",
            "514e0ea3ae01472f9a1f445587eda4f4",
            "0e9c3045714946169590856007323c7e",
            "79a39a0f3a164a6e8532d5d3a6a97acc",
            "1917c37ead9a4ed6b941193f2b9f3f6f",
            "c8ee82cbb52e4f719764ed11e0be1d92",
            "51c6fd1f8c9e452bb490b6a08367168f"
          ]
        },
        "outputId": "129de813-dc55-43c6-8ad6-0fafd7d8aab2"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                        train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                       train=False,\n",
        "                                       download=True,\n",
        "                                       transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=False,\n",
        "                                         num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse',\n",
        "           'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84dca248e17b42e69ce293893d6e52da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCNbrW3CSJk6"
      },
      "source": [
        "def trainModel(net, trainloader, lr, momentum, num_epochs):\n",
        "\n",
        "  # Define loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  # Define optimization algorithm\n",
        "  optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "  train_loss = []\n",
        "  for epoch in range(num_epochs):  # Loop over the dataset\n",
        "\n",
        "      running_loss = []\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # Zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Pass input data through model (forward pass)\n",
        "          outputs = net(inputs)\n",
        "          \n",
        "          # Compute loss (cross-entropy loss)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # Compute gradients (backward pass)\n",
        "          loss.backward()\n",
        "\n",
        "          # Update parameters (using computed gradients)\n",
        "          optimizer.step()\n",
        "          running_loss.append(loss.item())\n",
        "\n",
        "      # Store training loss\n",
        "      train_loss.append(np.mean(running_loss))\n",
        "      print('epoch {} | loss: {}'.format(epoch,\n",
        "                                         np.mean(running_loss)))\n",
        "\n",
        "  print('Finished Training')\n",
        "\n",
        "  return net, outputs, labels, train_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHsGHipZB-66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18849614-6257-4c7e-bbce-ebbfd25ec988"
      },
      "source": [
        "# Train ConvNet w/o batch normalization\n",
        "net, outputs, labels, train_loss = trainModel(net=net_original, trainloader=trainloader, lr=lr, momentum=momentum, num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 | loss: 2.238338841030393\n",
            "epoch 1 | loss: 2.124000420095539\n",
            "epoch 2 | loss: 2.0721957473320094\n",
            "epoch 3 | loss: 2.0408985536114215\n",
            "epoch 4 | loss: 2.0179495166430734\n",
            "epoch 5 | loss: 1.9942553534647913\n",
            "epoch 6 | loss: 1.9756645047171215\n",
            "epoch 7 | loss: 1.9511720357573383\n",
            "epoch 8 | loss: 1.933359710342096\n",
            "epoch 9 | loss: 1.9154285520011247\n",
            "epoch 10 | loss: 1.9051857468748636\n",
            "epoch 11 | loss: 1.8918812791959354\n",
            "epoch 12 | loss: 1.8813163520478888\n",
            "epoch 13 | loss: 1.872353206656261\n",
            "epoch 14 | loss: 1.861965880039286\n",
            "epoch 15 | loss: 1.8551467126475598\n",
            "epoch 16 | loss: 1.8465558678072658\n",
            "epoch 17 | loss: 1.8403626345701396\n",
            "epoch 18 | loss: 1.8302381572854969\n",
            "epoch 19 | loss: 1.824571268817373\n",
            "epoch 20 | loss: 1.8173769747488644\n",
            "epoch 21 | loss: 1.8101246356964111\n",
            "epoch 22 | loss: 1.8038389717095187\n",
            "epoch 23 | loss: 1.7984956407804438\n",
            "epoch 24 | loss: 1.7908304373375585\n",
            "epoch 25 | loss: 1.786528922014059\n",
            "epoch 26 | loss: 1.7830328309900687\n",
            "epoch 27 | loss: 1.778037604058511\n",
            "epoch 28 | loss: 1.772278580182172\n",
            "epoch 29 | loss: 1.7650353762655824\n",
            "epoch 30 | loss: 1.7599236621210228\n",
            "epoch 31 | loss: 1.7542339308789625\n",
            "epoch 32 | loss: 1.7510319988242724\n",
            "epoch 33 | loss: 1.7446506058447506\n",
            "epoch 34 | loss: 1.7401369465420042\n",
            "epoch 35 | loss: 1.7376599553536711\n",
            "epoch 36 | loss: 1.7306615041270539\n",
            "epoch 37 | loss: 1.7300770284175586\n",
            "epoch 38 | loss: 1.72059267612725\n",
            "epoch 39 | loss: 1.718921003330233\n",
            "epoch 40 | loss: 1.7147228767861844\n",
            "epoch 41 | loss: 1.7123973725009407\n",
            "epoch 42 | loss: 1.70538334240081\n",
            "epoch 43 | loss: 1.7011205522185968\n",
            "epoch 44 | loss: 1.6990484416878144\n",
            "epoch 45 | loss: 1.6924640173388585\n",
            "epoch 46 | loss: 1.6920267590950118\n",
            "epoch 47 | loss: 1.6857499925405162\n",
            "epoch 48 | loss: 1.6836009921609962\n",
            "epoch 49 | loss: 1.6792898557825437\n",
            "epoch 50 | loss: 1.6758952317440945\n",
            "epoch 51 | loss: 1.6717198087415368\n",
            "epoch 52 | loss: 1.6692168063293622\n",
            "epoch 53 | loss: 1.6670047819221099\n",
            "epoch 54 | loss: 1.6630974512437753\n",
            "epoch 55 | loss: 1.6596413124229783\n",
            "epoch 56 | loss: 1.655361724386118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnnxVvBSN4pq"
      },
      "source": [
        "# Train ConvNet w/ batch normalization\n",
        "net, outputs, labels, train_loss = trainModel(net=net_bn, trainloader=trainloader, lr=lr, momentum=momentum, num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6ovI_OcdHRz"
      },
      "source": [
        "# Train ConvNet w/ deep architecture\n",
        "net, outputs, labels, train_loss = trainModel(net=net_deep, trainloader=trainloader, lr=lr, momentum=momentum, num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTV5oCdT522T"
      },
      "source": [
        "# Visualize filters\n",
        "filters = net.conv1.weight.cpu().detach().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3pYqqTl6Vrb"
      },
      "source": [
        "fig = plt.figure(figsize=(16, 4))\n",
        "for i in range(64):\n",
        "  x = filters[i, :, :, :].transpose((1, 2, 0))\n",
        "  x = (x - x.min()) / (x - x.min()).max()\n",
        "  ax = fig.add_subplot(4, 16, i+1)\n",
        "  ax.axis('off')\n",
        "  ax.imshow(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATGl3_8GfgiP"
      },
      "source": [
        "def displayLoss(train_loss):\n",
        "    \n",
        "    plt.plot(range(len(train_loss)), train_loss, color='red', label='Train')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "displayLoss(train_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8_DfUvGhW15"
      },
      "source": [
        "# Test network on testing data\n",
        "\n",
        "correct = 0.\n",
        "total = 0.\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        test_images, test_labels = data\n",
        "        test_images = test_images.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "        test_outputs = net(test_images)\n",
        "        \n",
        "        # Compute predicted labels\n",
        "        _, predicted = torch.max(test_outputs.data, 1)\n",
        "        \n",
        "        # Update running totals of correct predictions and total predictions\n",
        "        total += test_labels.size(0)\n",
        "        correct += (predicted == test_labels).sum().item()\n",
        "\n",
        "test_acc = correct / total\n",
        "print('Test Accuracy: {}'.format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}